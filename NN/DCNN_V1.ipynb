{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCNN_V1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SveinungOverland/ZeroGO/blob/master/NN/DCNN_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kZxYTKroxJu",
        "colab_type": "text"
      },
      "source": [
        "# Deep Convolutional Neural Net for ZeroGO V1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjaefVx0oA3q",
        "colab_type": "code",
        "outputId": "ec6f7781-2749-4c8c-b43d-f65c5fa4d657",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cO_POI348NT",
        "colab_type": "text"
      },
      "source": [
        "## Layers and heads"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3TtJeEds7MU",
        "colab_type": "text"
      },
      "source": [
        "### Residual layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmZGNroLs_VA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_residual_layer(x):\n",
        "  res = layers.Conv2D(256, kernel_size=(3,3), padding='same')(x)\n",
        "  res = layers.BatchNormalization(axis=1)(res)\n",
        "  res = layers.ReLU()(res)\n",
        "  res = layers.Conv2D(256, kernel_size=(3,3), padding='same')(res)\n",
        "  res = layers.BatchNormalization(axis=1)(res)\n",
        "  res = layers.ReLU()(res)\n",
        "  res = layers.add([res, x])\n",
        "  return layers.ReLU()(res)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfCTQ7oP5G1x",
        "colab_type": "text"
      },
      "source": [
        "### Create trunk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLnWD23Q5KbW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_trunk(shape, nr_residual_layers, filters):\n",
        "  inputs = keras.Input(shape=shape)\n",
        "  x = layers.Conv2D(filters, kernel_size=(3,3), padding='same')(inputs)\n",
        "  x = layers.BatchNormalization(axis=1)(x)\n",
        "  x = layers.ReLU()(x)\n",
        "  for i in range(nr_residual_layers):\n",
        "    x = add_residual_layer(x)\n",
        "  return keras.Model(inputs, x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fo1Ur6xz45Nv",
        "colab_type": "text"
      },
      "source": [
        "### Create value head"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJ8eA_AV5ktR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_value_head(shape, filters):\n",
        "    return keras.Sequential([\n",
        "        layers.Conv2D(1, kernel_size=(1,1), padding='same'),\n",
        "        layers.BatchNormalization(axis=1),\n",
        "        layers.ReLU(),\n",
        "        layers.Dense(filters),\n",
        "        layers.ReLU(),\n",
        "        layers.Dense(1, activation=\"tanh\")\n",
        "    ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lztQJY_VUEZ0",
        "colab_type": "text"
      },
      "source": [
        "### Create policy head"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVAHaFKlUGgp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_policy_head(shape, filters):\n",
        "  return keras.Sequential([\n",
        "      layers.Conv2D(2, kernel_size=(1,1), padding='same'),\n",
        "      layers.BatchNormalization(axis=1),\n",
        "      layers.ReLU(),\n",
        "      layers.Dense(shape[0] * shape[1] + 1)\n",
        "  ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPhkCKZ7SwuG",
        "colab_type": "text"
      },
      "source": [
        "## Mode class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0C2YuVhS0no",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Mode:\n",
        "  Trunk = 0\n",
        "  Value = 1\n",
        "  Policy = 2\n",
        "  ValueHead = 3\n",
        "  PolicyHead = 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCBkPUeZuAon",
        "colab_type": "text"
      },
      "source": [
        "## Model class "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNHZDTLLuEx8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model:\n",
        "  def __init__(self, trunk, value_head, policy_head):    \n",
        "    # Can be choosen by mode\n",
        "    self.trunk = trunk # Is a model\n",
        "    self.value_head = value_head\n",
        "    self.policy_head = policy_head\n",
        "  \n",
        "    # Can also be choosen by mode\n",
        "    self.value_path = keras.Sequential([self.trunk, self.value_head])\n",
        "    self.policy_path = keras.Sequential([self.trunk, self.policy_head])\n",
        "    \n",
        "  def save(self, file_name: str):\n",
        "    print(\"Can't save yet\")\n",
        "    pass\n",
        "  \n",
        "#   def loss_fn(self, value_true, value_pred, policy_true, policy_pred):\n",
        "#     # (z - v)^2 - pi^T * log(p) + c*||O||^2, der z = self-play-winner, v = predicted value, pi = search probabilities, p = nn move probability, O = nn parameters (weights), c = parameter controlling the level of L2 weight regularisation to prevent overfitting\n",
        "#     # sum of mean-squared error and cross-entropy loss\n",
        "#     return keras.losses.MSE(y_true, y_pred) + keras.losses.categorical_crossentropy(policy_true, policy_pred) # v1\n",
        "#     pass\n",
        "  \n",
        "  def get_trunk_weights(self):\n",
        "    return self.trunk.get_weights()\n",
        "  \n",
        "  def __retrieve_net(self, mode):\n",
        "    if mode == Mode.Trunk:\n",
        "      net = self.trunk\n",
        "    elif mode == Mode.Value:\n",
        "      net = self.value_path\n",
        "    elif mode == Mode.Policy:\n",
        "      net = self.policy_path\n",
        "    elif mode == Mode.ValueHead:\n",
        "      net = self.value_head\n",
        "    elif mode == Mode.PolicyHead:\n",
        "      net = self.policy_head\n",
        "    else:\n",
        "      print(\"No acceptible mode given!\")\n",
        "      raise Exception(\"No acceptible mode given!\")\n",
        "    return net\n",
        "  \n",
        "  def train(self, mode: Mode, loss):\n",
        "    net = self.__retrieve_net(mode)\n",
        "    tape = tf.GradientTape()\n",
        "    gradients = tape.gradient(loss, net.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, net.trainable_variables))\n",
        "  \n",
        "  def predict(self, mode, X):\n",
        "    net = self.__retrieve_net(mode)\n",
        "    return net.predict(X)\n",
        "  \n",
        "  def describe(self, mode):\n",
        "    net = self.__retrieve_net(mode)\n",
        "    return net.summary()\n",
        "  \n",
        "  @classmethod\n",
        "  def load(cls, filename):\n",
        "    print(\"Can't load yet\")\n",
        "    pass\n",
        "  \n",
        "  @classmethod\n",
        "  def create(cls, shape=(5,5,7), nr_residual_layers=10, filters=256):\n",
        "    trunk = create_trunk(shape, nr_residual_layers, filters)\n",
        "    value_head = create_value_head(shape, filters)\n",
        "    policy_head = create_policy_head(shape, filters)\n",
        "    return cls(trunk, value_head, policy_head)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MC2Z6WtrPMm2",
        "colab_type": "text"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTzGWmzWPSVO",
        "colab_type": "code",
        "outputId": "86e1f184-a2ea-424d-e147-781fb6066543",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        }
      },
      "source": [
        "model = Model.create(shape=(2,2,1), nr_residual_layers=2)\n",
        "\n",
        "state = np.array([\n",
        "    [[0], [1]],\n",
        "    [[0], [0]]\n",
        "])\n",
        "print(\"Shape: \", state.shape)\n",
        "\n",
        "print(\"Value summary: \", model.describe(Mode.Value))\n",
        "print()\n",
        "print(\"Policy summary: \", model.describe(Mode.Policy))\n",
        "print()\n",
        "print(\"Value: \", model.predict(Mode.Value, state))\n",
        "print(\"Policy: \", model.predict(Mode.Policy, state))"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape:  (2, 2, 1)\n",
            "Model: \"sequential_66\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_12 (Model)             (None, 2, 2, 256)         2362920   \n",
            "_________________________________________________________________\n",
            "sequential_64 (Sequential)   (None, 2, 2, 1)           1034      \n",
            "=================================================================\n",
            "Total params: 2,363,954\n",
            "Trainable params: 2,363,930\n",
            "Non-trainable params: 24\n",
            "_________________________________________________________________\n",
            "Value summary:  None\n",
            "\n",
            "Model: \"sequential_67\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_12 (Model)             (None, 2, 2, 256)         2362920   \n",
            "_________________________________________________________________\n",
            "sequential_65 (Sequential)   (None, 2, 2, 5)           537       \n",
            "=================================================================\n",
            "Total params: 2,363,457\n",
            "Trainable params: 2,363,433\n",
            "Non-trainable params: 24\n",
            "_________________________________________________________________\n",
            "Policy summary:  None\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-116-4197da592b18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Policy summary: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPolicy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Value: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mValue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Policy: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-114-50685208d51d>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, mode, X)\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__retrieve_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    713\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_or_infer_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m     x, _, _ = model._standardize_user_data(\n\u001b[0;32m--> 715\u001b[0;31m         x, check_steps=True, steps_name='steps', steps=steps)\n\u001b[0m\u001b[1;32m    716\u001b[0m     return predict_loop(\n\u001b[1;32m    717\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2470\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2472\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    563\u001b[0m                            \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    566\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected model_12_input to have 4 dimensions, but got array with shape (2, 2, 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waIKQFX1TMA_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}