{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCNN_V1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SveinungOverland/ZeroGO/blob/master/NN/DCNN_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kZxYTKroxJu",
        "colab_type": "text"
      },
      "source": [
        "# Deep Convolutional Neural Net for ZeroGO V1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjaefVx0oA3q",
        "colab_type": "code",
        "outputId": "3aa39e65-bbe1-4379-c00d-0f0bad6a6123",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZdyaQu_CaRG",
        "colab_type": "text"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "im1CbpDyCcdK",
        "colab_type": "text"
      },
      "source": [
        "### Batch normalization axis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMoUw7kRChTS",
        "colab_type": "text"
      },
      "source": [
        "Batch normalization only supports NHWC tensor on CPU\n",
        "(Num_samples, Height, Width, Channels) (channel_last)\n",
        "\n",
        "On GPU however NCHW is faster\n",
        "(Num_samples, Channels, Height, Width)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOgzRAlIFkMf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataFormats:\n",
        "  ChannelsFirst = 'channels_first'\n",
        "  ChannelsLast = 'channels_last'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjnGM7HADQaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_format_axis(data_format):\n",
        "  return 1 if data_format == DataFormats.ChannelsFirst else 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cO_POI348NT",
        "colab_type": "text"
      },
      "source": [
        "## Layers and heads"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3TtJeEds7MU",
        "colab_type": "text"
      },
      "source": [
        "### Residual layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmZGNroLs_VA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_residual_layer(x, data_format, filters, kernel_size):\n",
        "  bn_axis = data_format_axis(data_format)\n",
        "  res = layers.Conv2D(filters, kernel_size=kernel_size, padding='same', data_format=data_format)(x)\n",
        "  res = layers.BatchNormalization(axis=bn_axis)(res)\n",
        "  res = layers.ReLU()(res)\n",
        "  res = layers.Conv2D(filters, kernel_size=kernel_size, padding='same', data_format=data_format)(res)\n",
        "  res = layers.BatchNormalization(axis=bn_axis)(res)\n",
        "  res = layers.ReLU()(res)\n",
        "  res = layers.add([res, x])\n",
        "  return layers.ReLU()(res)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfCTQ7oP5G1x",
        "colab_type": "text"
      },
      "source": [
        "### Create trunk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLnWD23Q5KbW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_trunk(shape, nr_residual_layers, filters, data_format, kernel_size):\n",
        "  # Add lambda layer here to transpose NHWC to NCHW automatically\n",
        "  bn_axis = data_format_axis(data_format)\n",
        "  inputs = keras.Input(shape=shape)\n",
        "  x = layers.Conv2D(filters, kernel_size=kernel_size, padding='same', data_format=data_format)(inputs)\n",
        "  x = layers.BatchNormalization(axis=bn_axis)(x)\n",
        "  x = layers.ReLU()(x)\n",
        "  for i in range(nr_residual_layers):\n",
        "    x = add_residual_layer(x, data_format, filters, kernel_size)\n",
        "  return keras.Model(inputs, x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fo1Ur6xz45Nv",
        "colab_type": "text"
      },
      "source": [
        "### Create value head"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJ8eA_AV5ktR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_value_head(shape, filters, data_format, kernel_size):\n",
        "  bn_axis = data_format_axis(data_format)\n",
        "  return keras.Sequential([\n",
        "      layers.Conv2D(1, kernel_size=(1,1), padding='same', data_format=data_format),\n",
        "      layers.BatchNormalization(axis=bn_axis),\n",
        "      layers.ReLU(),\n",
        "      layers.Dense(filters),\n",
        "      layers.ReLU(),\n",
        "      layers.GlobalMaxPooling2D(data_format),\n",
        "      layers.Flatten(),\n",
        "      layers.Dense(1, activation=\"tanh\")\n",
        "  ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lztQJY_VUEZ0",
        "colab_type": "text"
      },
      "source": [
        "### Create policy head"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVAHaFKlUGgp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_policy_head(shape, filters, data_format, kernel_size):\n",
        "  bn_axis = data_format_axis(data_format)\n",
        "  return keras.Sequential([\n",
        "      layers.Conv2D(2, kernel_size=(1,1), padding='same', data_format=data_format),\n",
        "      layers.BatchNormalization(axis=bn_axis),\n",
        "      layers.ReLU(),\n",
        "      layers.GlobalMaxPooling2D(data_format),\n",
        "      layers.Flatten(),\n",
        "      layers.Dense(shape[0] * shape[1] + 1, activation='softmax')\n",
        "  ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPhkCKZ7SwuG",
        "colab_type": "text"
      },
      "source": [
        "## Mode class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0C2YuVhS0no",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Mode:\n",
        "  Trunk = 0\n",
        "  Value = 1\n",
        "  Policy = 2\n",
        "  ValueHead = 3\n",
        "  PolicyHead = 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCBkPUeZuAon",
        "colab_type": "text"
      },
      "source": [
        "## Model class "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNHZDTLLuEx8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model:\n",
        "  def __init__(self, trunk, value_head, policy_head, data_format, kernel_size):    \n",
        "    # Can be choosen by mode\n",
        "    self.trunk = trunk # Is a model\n",
        "    self.value_head = value_head\n",
        "    self.policy_head = policy_head\n",
        "  \n",
        "    self.data_format = data_format\n",
        "    self.kernel_size = kernel_size\n",
        "  \n",
        "    # Can also be choosen by mode\n",
        "    self.value_path = keras.Sequential([self.trunk, self.value_head])\n",
        "    self.policy_path = keras.Sequential([self.trunk, self.policy_head])\n",
        "    \n",
        "  def save(self, file_name: str, overwrite=True):\n",
        "    self.__retrieve_net(Mode.Trunk).save_weights(file_name + \"/trunk/trunk\", overwrite=overwrite)\n",
        "    self.__retrieve_net(Mode.ValueHead).save_weights(file_name + \"/value/value\", overwrite=overwrite)\n",
        "    self.__retrieve_net(Mode.PolicyHead).save_weights(file_name + \"/policy/policy\", overwrite=overwrite)\n",
        "\n",
        "#   def loss_fn(self, value_true, value_pred, policy_true, policy_pred):\n",
        "#     # (z - v)^2 - pi^T * log(p) + c*||O||^2, der z = self-play-winner, v = predicted value, pi = search probabilities, p = nn move probability, O = nn parameters (weights), c = parameter controlling the level of L2 weight regularisation to prevent overfitting\n",
        "#     # sum of mean-squared error and cross-entropy loss\n",
        "#     return keras.losses.MSE(y_true, y_pred) + keras.losses.categorical_crossentropy(policy_true, policy_pred) # v1\n",
        "#     pass\n",
        "  \n",
        "  def get_trunk_weights(self):\n",
        "    return self.trunk.get_weights()\n",
        "  \n",
        "  def __retrieve_net(self, mode):\n",
        "    if mode == Mode.Trunk:\n",
        "      net = self.trunk\n",
        "    elif mode == Mode.Value:\n",
        "      net = self.value_path\n",
        "    elif mode == Mode.Policy:\n",
        "      net = self.policy_path\n",
        "    elif mode == Mode.ValueHead:\n",
        "      net = self.value_head\n",
        "    elif mode == Mode.PolicyHead:\n",
        "      net = self.policy_head\n",
        "    else:\n",
        "      print(\"No acceptible mode given!\")\n",
        "      raise Exception(\"No acceptible mode given!\")\n",
        "    return net\n",
        "  \n",
        "  def train(self, mode: Mode, loss):\n",
        "    net = self.__retrieve_net(mode)\n",
        "    tape = tf.GradientTape()\n",
        "    gradients = tape.gradient(loss, net.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, net.trainable_variables))\n",
        "  \n",
        "  def predict(self, mode, X):\n",
        "    net = self.__retrieve_net(mode)\n",
        "    return net.predict(X)\n",
        "  \n",
        "  def describe(self, mode):\n",
        "    net = self.__retrieve_net(mode)\n",
        "    return net.summary()\n",
        "  \n",
        "  def load(self, file_name):\n",
        "    self.__retrieve_net(Mode.PolicyHead).load_weights(file_name + \"/policy/policy\")\n",
        "    self.__retrieve_net(Mode.ValueHead).load_weights(file_name + \"/value/value\")\n",
        "    self.__retrieve_net(Mode.Trunk).load_weights(file_name + \"/trunk/trunk\")\n",
        "    return self\n",
        "  \n",
        "  @classmethod\n",
        "  def create(cls, shape=(5,5,7), nr_residual_layers=10, kernel_size=(3,3), filters=256, data_format=DataFormats.ChannelsLast):\n",
        "    trunk = create_trunk(shape, nr_residual_layers, filters, data_format, kernel_size)\n",
        "    value_head = create_value_head(shape, filters, data_format, kernel_size)\n",
        "    policy_head = create_policy_head(shape, filters, data_format, kernel_size)\n",
        "    return cls(trunk, value_head, policy_head, data_format, kernel_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MC2Z6WtrPMm2",
        "colab_type": "text"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTzGWmzWPSVO",
        "colab_type": "code",
        "outputId": "d82203bc-f2e6-4f1e-e5cb-00c2394871e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        }
      },
      "source": [
        "model = Model.create(shape=(5, 5, 7), nr_residual_layers=5, data_format=DataFormats.ChannelsLast)\n",
        "\n",
        "state = np.array([\n",
        "    [[0,1],\n",
        "    [0,0]]\n",
        "]).reshape(1,2,2,1)\n",
        "\n",
        "print(\"Shape: \", state.shape)\n",
        "\n",
        "print(\"Value summary: \", model.describe(Mode.Value))\n",
        "print()\n",
        "print(\"Policy summary: \", model.describe(Mode.Policy))\n",
        "# print()\n",
        "# print(\"Value: \", model.predict(Mode.Value, state))\n",
        "# print(\"Policy: \", model.predict(Mode.Policy, state))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape:  (1, 2, 2, 1)\n",
            "Model: \"sequential_56\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_16 (Model)             (1, 5, 5, 256)            11839488  \n",
            "_________________________________________________________________\n",
            "sequential_54 (Sequential)   (1, 1)                    1030      \n",
            "=================================================================\n",
            "Total params: 11,840,518\n",
            "Trainable params: 11,829,764\n",
            "Non-trainable params: 10,754\n",
            "_________________________________________________________________\n",
            "Value summary:  None\n",
            "\n",
            "Model: \"sequential_57\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_16 (Model)             (1, 5, 5, 256)            11839488  \n",
            "_________________________________________________________________\n",
            "sequential_55 (Sequential)   (1, 26)                   600       \n",
            "=================================================================\n",
            "Total params: 11,840,088\n",
            "Trainable params: 11,829,332\n",
            "Non-trainable params: 10,756\n",
            "_________________________________________________________________\n",
            "Policy summary:  None\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}